{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-06-05T14:47:48.758754Z",
     "start_time": "2025-06-05T14:47:48.727196Z"
    }
   },
   "source": [
    "%load_ext dotenv\n",
    "%dotenv"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-05T14:49:14.697610Z",
     "start_time": "2025-06-05T14:49:12.207294Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain.chains.llm import LLMChain\n",
    "\n",
    "from langchain.memory import ConversationSummaryMemory\n",
    "\n",
    "from langchain.globals import set_verbose\n",
    "set_verbose(True)"
   ],
   "id": "7f78917dc9d7fbdb",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-05T14:49:50.970825Z",
     "start_time": "2025-06-05T14:49:50.343404Z"
    }
   },
   "cell_type": "code",
   "source": "chat = ChatOpenAI(model='gpt-4o-mini', seed=365, temperature=0, max_tokens=100)",
   "id": "c83d168f56207bc8",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-05T14:51:24.712820Z",
     "start_time": "2025-06-05T14:51:24.679985Z"
    }
   },
   "cell_type": "code",
   "source": [
    "TEMPLATE = \"\"\"\n",
    "The following is a friendly conversation between a human and an AI. \n",
    "The AI is talkative and provides lots of specific details from its context. \n",
    "If the AI does not know the answer to a question, it truthfully says it does not know.\n",
    "\n",
    "Current conversation:\n",
    "{message_log}\n",
    "\n",
    "Human:\n",
    "{question}\n",
    "\n",
    "AI:\n",
    "\"\"\""
   ],
   "id": "b57263ea40df119d",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-05T14:51:44.127746Z",
     "start_time": "2025-06-05T14:51:44.091715Z"
    }
   },
   "cell_type": "code",
   "source": "prompt_template = PromptTemplate.from_template(template=TEMPLATE)",
   "id": "a8bad1357d0af3b1",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-05T14:52:35.033673Z",
     "start_time": "2025-06-05T14:52:34.972604Z"
    }
   },
   "cell_type": "code",
   "source": "chat_memory = ConversationSummaryMemory(llm=ChatOpenAI(), memory_key='message_log',return_messages=False)",
   "id": "f0b29f662198dfef",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\matsv\\AppData\\Local\\Temp\\ipykernel_13044\\1721248332.py:1: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  chat_memory = ConversationSummaryMemory(llm=ChatOpenAI(), memory_key='message_log',return_messages=False)\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-05T14:55:17.347818Z",
     "start_time": "2025-06-05T14:55:17.331552Z"
    }
   },
   "cell_type": "code",
   "source": "chat_memory.load_memory_variables({})",
   "id": "d2fbb9f826242ab0",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'message_log': \"The human asks the AI for an interesting fact they probably didn't know about. The AI shares that honey never spoils and gives the example of ancient pots of honey in Egyptian tombs that are still edible after 3,000 years. Honey's long shelf life is attributed to its low moisture content and acidic pH, creating an environment hostile to bacteria and microorganisms. Honey could potentially last indefinitely in your pantry.\"}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-05T14:53:42.292907Z",
     "start_time": "2025-06-05T14:53:42.273889Z"
    }
   },
   "cell_type": "code",
   "source": "chain= LLMChain(llm=chat,prompt=prompt_template, memory=chat_memory)",
   "id": "847ef2d8bbfbc2fb",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\matsv\\AppData\\Local\\Temp\\ipykernel_13044\\255199374.py:1: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
      "  chain= LLMChain(llm=chat,prompt=prompt_template, memory=chat_memory)\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-05T14:54:08.587896Z",
     "start_time": "2025-06-05T14:54:02.778528Z"
    }
   },
   "cell_type": "code",
   "source": [
    "chain.invoke({'question':\"Can you give me an interesting fact I probably didn't know about?\"})\n",
    "# chain.invoke({'question':\"Can you elaborate a bit more on this fact?\"})"
   ],
   "id": "fafd24c96c10f8da",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new LLMChain chain...\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3m\n",
      "The following is a friendly conversation between a human and an AI. \n",
      "The AI is talkative and provides lots of specific details from its context. \n",
      "If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "\n",
      "Human:\n",
      "Can you give me an interesting fact I probably didn't know about?\n",
      "\n",
      "AI:\n",
      "\u001B[0m\n",
      "\n",
      "\n",
      "\u001B[1m> Entering new LLMChain chain...\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mProgressively summarize the lines of conversation provided, adding onto the previous summary returning a new summary.\n",
      "\n",
      "EXAMPLE\n",
      "Current summary:\n",
      "The human asks what the AI thinks of artificial intelligence. The AI thinks artificial intelligence is a force for good.\n",
      "\n",
      "New lines of conversation:\n",
      "Human: Why do you think artificial intelligence is a force for good?\n",
      "AI: Because artificial intelligence will help humans reach their full potential.\n",
      "\n",
      "New summary:\n",
      "The human asks what the AI thinks of artificial intelligence. The AI thinks artificial intelligence is a force for good because it will help humans reach their full potential.\n",
      "END OF EXAMPLE\n",
      "\n",
      "Current summary:\n",
      "\n",
      "\n",
      "New lines of conversation:\n",
      "Human: Can you give me an interesting fact I probably didn't know about?\n",
      "AI: Sure! Did you know that honey never spoils? Archaeologists have found pots of honey in ancient Egyptian tombs that are over 3,000 years old and still perfectly edible! Honey's long shelf life is due to its low moisture content and acidic pH, which create an inhospitable environment for bacteria and microorganisms. So, if you have a jar of honey sitting in your pantry, it could last indefinitely!\n",
      "\n",
      "New summary:\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'question': \"Can you give me an interesting fact I probably didn't know about?\",\n",
       " 'message_log': '',\n",
       " 'text': \"Sure! Did you know that honey never spoils? Archaeologists have found pots of honey in ancient Egyptian tombs that are over 3,000 years old and still perfectly edible! Honey's long shelf life is due to its low moisture content and acidic pH, which create an inhospitable environment for bacteria and microorganisms. So, if you have a jar of honey sitting in your pantry, it could last indefinitely!\"}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "4c216eadbd397ce"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
