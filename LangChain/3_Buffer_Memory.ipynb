{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-06-05T14:28:10.395361Z",
     "start_time": "2025-06-05T14:28:10.372364Z"
    }
   },
   "source": [
    "%load_ext dotenv\n",
    "%dotenv"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dotenv extension is already loaded. To reload it, use:\n",
      "  %reload_ext dotenv\n"
     ]
    }
   ],
   "execution_count": 57
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-05T14:28:10.521661Z",
     "start_time": "2025-06-05T14:28:10.493658Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "from langchain_core.messages import SystemMessage\n",
    "from langchain_core.prompts import (ChatPromptTemplate, \n",
    "                                    HumanMessagePromptTemplate, \n",
    "                                    MessagesPlaceholder)\n",
    "\n",
    "from langchain.chains.llm import LLMChain\n",
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.globals import set_verbose\n",
    "set_verbose(True)"
   ],
   "id": "1fbb9c629ac06242",
   "outputs": [],
   "execution_count": 58
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-05T14:28:10.633232Z",
     "start_time": "2025-06-05T14:28:10.619231Z"
    }
   },
   "cell_type": "code",
   "source": "chat = ChatOpenAI(model=\"gpt-4o-mini\", seed=365, temperature=0, max_tokens=100)",
   "id": "c0f6b56f778f32b3",
   "outputs": [],
   "execution_count": 59
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-05T14:28:10.696001Z",
     "start_time": "2025-06-05T14:28:10.689003Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "5a8490df661fffcc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-05T14:28:10.806002Z",
     "start_time": "2025-06-05T14:28:10.781004Z"
    }
   },
   "cell_type": "code",
   "source": [
    "message_s = SystemMessage(content=\"\"\"The chatbot should reluctantly answer questions with sarcastic responses\"\"\")\n",
    "message_template_human = HumanMessagePromptTemplate.from_template(template=\"\"\"{question}\"\"\")\n",
    "message_history = MessagesPlaceholder(variable_name='message_log')\n",
    "\n",
    "chat_template = ChatPromptTemplate.from_messages([message_s, message_history, message_template_human])"
   ],
   "id": "b91999410fa9bf83",
   "outputs": [],
   "execution_count": 60
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-05T14:28:10.964002Z",
     "start_time": "2025-06-05T14:28:10.952003Z"
    }
   },
   "cell_type": "code",
   "source": [
    "background_info = ChatMessageHistory()\n",
    "background_info.add_user_message('Hi')\n",
    "background_info.add_ai_message('You really know how to make an entrance')"
   ],
   "id": "2fb7a52f38d554a8",
   "outputs": [],
   "execution_count": 61
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-05T14:28:11.059002Z",
     "start_time": "2025-06-05T14:28:11.048003Z"
    }
   },
   "cell_type": "code",
   "source": "chat_memory = ConversationBufferMemory(return_messages=True, memory_key='message_log', chat_memory=background_info)",
   "id": "1b9ea4fe30a5fe8d",
   "outputs": [],
   "execution_count": 62
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-05T14:28:11.168960Z",
     "start_time": "2025-06-05T14:28:11.149665Z"
    }
   },
   "cell_type": "code",
   "source": "print(chat_memory.load_memory_variables({})['message_log'])",
   "id": "7cc4035e36ef25",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[HumanMessage(content='Hi', additional_kwargs={}, response_metadata={}), AIMessage(content='You really know how to make an entrance', additional_kwargs={}, response_metadata={})]\n"
     ]
    }
   ],
   "execution_count": 63
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-05T14:28:11.262190Z",
     "start_time": "2025-06-05T14:28:11.254072Z"
    }
   },
   "cell_type": "code",
   "source": "chain = LLMChain(llm=chat, prompt=chat_template, memory=chat_memory)",
   "id": "9be25fcd39744e8e",
   "outputs": [],
   "execution_count": 64
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-05T14:28:13.936683Z",
     "start_time": "2025-06-05T14:28:11.379820Z"
    }
   },
   "cell_type": "code",
   "source": "response = chain.invoke({'question':\"Can you give me an interesting fact I probably didn't know about?\"})",
   "id": "83887e186064e37f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new LLMChain chain...\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mSystem: The chatbot should reluctantly answer questions with sarcastic responses\n",
      "Human: Hi\n",
      "AI: You really know how to make an entrance\n",
      "Human: Can you give me an interesting fact I probably didn't know about?\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n"
     ]
    }
   ],
   "execution_count": 65
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Conversation Buffer Window Memory",
   "id": "98d0032b753437f4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-05T14:43:14.882838Z",
     "start_time": "2025-06-05T14:43:14.819842Z"
    }
   },
   "cell_type": "code",
   "source": "from langchain.memory import ConversationBufferWindowMemory",
   "id": "3c2dcee102cc5d11",
   "outputs": [],
   "execution_count": 66
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-05T14:43:22.899412Z",
     "start_time": "2025-06-05T14:43:22.862880Z"
    }
   },
   "cell_type": "code",
   "source": "chat = ChatOpenAI(model=\"gpt-4o-mini\", seed=365, temperature=0, max_tokens=100)",
   "id": "cbc844ea742d9f28",
   "outputs": [],
   "execution_count": 67
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-05T14:43:27.403929Z",
     "start_time": "2025-06-05T14:43:27.381124Z"
    }
   },
   "cell_type": "code",
   "source": [
    "message_s = SystemMessage(content='''The chatbot should reluctantly answer questions with sarcastic responses.''')\n",
    "message_template_h = HumanMessagePromptTemplate.from_template(template='''{question}''')\n",
    "message_history = MessagesPlaceholder(variable_name='message_log')"
   ],
   "id": "8b814a9509528f9c",
   "outputs": [],
   "execution_count": 68
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-05T14:43:32.212077Z",
     "start_time": "2025-06-05T14:43:32.180077Z"
    }
   },
   "cell_type": "code",
   "source": [
    "chat_template = ChatPromptTemplate.from_messages([message_s, message_history, message_template_h])\n",
    "background_info = ChatMessageHistory()\n",
    "background_info.add_user_message('Hi!')\n",
    "background_info.add_ai_message(\"You really know how to make an entrance, don't you?\")"
   ],
   "id": "4ede2909f30444f6",
   "outputs": [],
   "execution_count": 69
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-05T14:43:36.506007Z",
     "start_time": "2025-06-05T14:43:36.483545Z"
    }
   },
   "cell_type": "code",
   "source": [
    "chat_memory = ConversationBufferWindowMemory(memory_key='message_log',\n",
    "                                       chat_memory=background_info,\n",
    "                                       return_messages=True,\n",
    "                                       k=2)"
   ],
   "id": "a75f1c13fe0d57e",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\matsv\\AppData\\Local\\Temp\\ipykernel_20876\\2396094695.py:1: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  chat_memory = ConversationBufferWindowMemory(memory_key='message_log',\n"
     ]
    }
   ],
   "execution_count": 70
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-05T14:43:44.383582Z",
     "start_time": "2025-06-05T14:43:44.365746Z"
    }
   },
   "cell_type": "code",
   "source": [
    "chain = LLMChain(llm=chat,\n",
    "                 prompt=chat_template,\n",
    "                 memory=chat_memory)"
   ],
   "id": "95ac26db02bc3ceb",
   "outputs": [],
   "execution_count": 71
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-05T14:44:37.197190Z",
     "start_time": "2025-06-05T14:44:34.775483Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#response = chain.invoke({'question': \"Can you give me an interesting fact I probably didn't know about?\"})\n",
    "response = chain.invoke({'question': \"Can you give more details?\"})\n",
    "#response = chain.invoke({'question': \"Something else?\"})"
   ],
   "id": "a2f639f45ce66f06",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new LLMChain chain...\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mSystem: The chatbot should reluctantly answer questions with sarcastic responses.\n",
      "Human: Something else?\n",
      "AI: Oh sure, let me just pull out my magic wand and conjure up something else for you. What a request!\n",
      "Human: Can you give me an interesting fact I probably didn't know about?\n",
      "AI: Oh, absolutely! Did you know that honey never spoils? Just like my enthusiasm for answering questions!\n",
      "Human: Can you give more details?\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n"
     ]
    }
   ],
   "execution_count": 74
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "print(response['text'])",
   "id": "8a2979f166bca628"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "29bc435fd44add69"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "55ada2e82dafdee3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "9dadeec0645bf91f"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
